{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from selenium import webdriver\n",
      "from selenium.webdriver.common.keys import Keys\n",
      "from selenium.webdriver.common.by import By\n",
      "from selenium.webdriver.support.ui import WebDriverWait # available since 2.4.0\n",
      "from selenium.webdriver.support import expected_conditions as EC # available since 2.26.0\n",
      "\n",
      "import parse\n",
      "import json\n",
      "import os\n",
      "import sys\n",
      "\n",
      "from datetime import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "OUT_DIR = os.path.join(os.getcwd(),'house_clerk_search_results')\n",
      "if not os.path.exists(OUT_DIR):\n",
      "    os.mkdir(OUT_DIR)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def go_to_url(driver, url):\n",
      "    driver.get(search_url)\n",
      "\n",
      "def search_begin(driver):\n",
      "    search_button = driver.find_element_by_name('ctl00$cphMain$btnSearch')\n",
      "    search_button.click()\n",
      "    \n",
      "def next_page(driver):\n",
      "    paging_row = driver.find_element_by_css_selector('.pagingRow')\n",
      "    paging_row_td = paging_row.find_element_by_tag_name('td')\n",
      "    data_pager = paging_row_td.find_element_by_tag_name('span')\n",
      "    pages = data_pager.find_elements_by_xpath('*')\n",
      "    page_tags = [e.tag_name for e in pages]\n",
      "    next_page = pages[page_tags.index('span') + 1]\n",
      "    next_page.click()\n",
      "\n",
      "def end_count(driver):\n",
      "    search_records = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CLASS_NAME, \"searchRecords\")))\n",
      "    #search_records = driver.find_element_by_class_name('')\n",
      "    search_records_text = search_records.text\n",
      "    results = parse.parse(\"Records {} through {} of {}\", search_records_text)\n",
      "    if results[1] == results[2]:\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "def select_search_results_element(driver):\n",
      "    search_results = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.ID, \"search_results\")))\n",
      "    search_results_body = search_results.find_element_by_tag_name('tbody')\n",
      "    return search_results_body\n",
      "    \n",
      "def scrape_rows(row_elements):\n",
      "    for tr in row_elements:\n",
      "        row = {'texts':tuple(),'urls':tuple()}\n",
      "        for td in tr.find_elements_by_tag_name('td'):\n",
      "            cell_text = td.text\n",
      "            row['texts'] += (cell_text,)\n",
      "            url = None\n",
      "            try: \n",
      "                url = td.find_element_by_tag_name('a').get_attribute('href')\n",
      "            except:\n",
      "                pass\n",
      "            row['urls'] += (url,)\n",
      "        yield row\n",
      "    \n",
      "def scrape_table(table_element):\n",
      "    search_results = table_element.find_elements_by_tag_name('tr')\n",
      "    header_row = search_results[0]\n",
      "    data_rows = [row for row in scrape_rows(search_results[1:-1])]\n",
      "    paging_row = search_results[-1]\n",
      "    headers = [td.text for td in header_row.find_elements_by_tag_name('font')]\n",
      "    table = []\n",
      "    for row in data_rows:\n",
      "        row_dict = {k:{} for k in headers}\n",
      "        for key,text_val,url_val in zip(headers,row['texts'],row['urls']):\n",
      "            row_dict[key]['text'] = text_val\n",
      "            row_dict[key]['url'] = url_val\n",
      "        table.append(row_dict)\n",
      "    return table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_url = 'http://clerk.house.gov/public_disc/financial-search.aspx'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "driver = webdriver.Firefox()\n",
      "begin_time = datetime.strftime(datetime.now(), '%Y%m%d_%H%M%S')\n",
      "\n",
      "go_to_url(driver, search_url)\n",
      "search_begin(driver)\n",
      "\n",
      "page = 1\n",
      "\n",
      "done = False\n",
      "\n",
      "while not done:\n",
      "    table = scrape_table(select_search_results_element(driver))\n",
      "    #should have zfill'd to three characters, probably more!\n",
      "    out_fname = 'results_{begin_time}_{page}.json'.format(begin_time=begin_time, page=str(page).zfill(2))\n",
      "    json.dump(table, open(os.path.join(OUT_DIR, out_fname),'w'))\n",
      "    done = end_count(driver)\n",
      "    next_page(driver)\n",
      "    page += 1\n",
      "\n",
      "#result_count = count_results(\n",
      "#while row_count == 20:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    }
   ],
   "metadata": {}
  }
 ]
}